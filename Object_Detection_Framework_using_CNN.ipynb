{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9940829,
          "sourceType": "datasetVersion",
          "datasetId": 5529429
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Object Detection Framework using CNN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zero00502/Sonar-detection/blob/main/Object_Detection_Framework_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sierra022_sonar_imaging_mine_detection_path = kagglehub.dataset_download('sierra022/sonar-imaging-mine-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "A0RjyGzxzebc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code provides a solid foundation for training an object detection model using the provided image and annotation data. You can now proceed to build and train the actual model, using the prepared data and appropriate neural network architectures.\n",
        "\n",
        "> The code imports necessary libraries for image processing, neural networks, data manipulation, and model evaluation.\n",
        "\n",
        "    It defines paths to the image and annotation directories.\n",
        "    \n",
        "    The load_annotations function reads and parses annotation files.\n",
        "    \n",
        "    The data preparation steps involve loading images and annotations, padding annotations to ensure consistent shapes, converting data to NumPy arrays, and splitting data into training and testing sets.\n",
        "    \n",
        "    The custom data generator class is used to efficiently batch the data during training.\n",
        "    \n",
        "    Data generators are created for training and testing sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ksn1ZP2wzebd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Import Necessary Libraries:\n",
        "\n",
        "    os: Provides functions for interacting with the operating system, such as file and directory operations.\n",
        "    \n",
        "    cv2: Open-source computer vision library for image processing and analysis.\n",
        "    \n",
        "    numpy: Numerical Python library for working with arrays and matrices.\n",
        "    \n",
        "    tensorflow.keras.models: Contains classes for creating and training neural network models.\n",
        "    \n",
        "    tensorflow.keras.layers: Provides various layers for building neural networks, such as convolutional, pooling, and fully connected layers.\n",
        "    \n",
        "    tensorflow.keras.preprocessing.image: Offers functions for preprocessing image data, including data augmentation.\n",
        "    \n",
        "    tensorflow.keras.utils: Contains utility functions for working with Keras models and data.\n",
        "    \n",
        "    sklearn.model_selection: Provides tools for splitting data into training and testing sets.\n",
        "    \n",
        "> Define Paths:\n",
        "\n",
        "    image_dir\n",
        "\n",
        "    : Specifies the directory containing the image files.\n",
        "    annotation_dir: Specifies the directory containing the corresponding annotation files.\n",
        "\n",
        "> Load Annotations Function:\n",
        "\n",
        "    load_annotations(annotation_file):\n",
        "        Reads the lines from the specified annotation file.\n",
        "        Parses each line to extract the class ID, bounding box center coordinates, and dimensions.\n",
        "        Appends the extracted annotation information to a list.\n",
        "        Returns the list of annotations."
      ],
      "metadata": {
        "id": "aVrP8lEozebf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Define the paths to your data\n",
        "image_dir = '/kaggle/input/sonar-imaging-mine-detection/obj/obj/'\n",
        "annotation_dir = '/kaggle/input/sonar-imaging-mine-detection/obj/obj/'\n",
        "\n",
        "\n",
        "def load_annotations(annotation_file):\n",
        "  \"\"\"Loads annotations from a text file.\"\"\"\n",
        "  with open(annotation_file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  annotations = []\n",
        "  for line in lines:\n",
        "    parts = line.strip().split()\n",
        "    class_id = int(parts[0])\n",
        "    x_center = float(parts[1])\n",
        "    y_center = float(parts[2])\n",
        "    width = float(parts[3])\n",
        "    height = float(parts[4])\n",
        "    annotations.append([class_id, x_center, y_center, width, height])\n",
        "  return annotations"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T05:08:04.322875Z",
          "iopub.execute_input": "2024-10-01T05:08:04.323363Z",
          "iopub.status.idle": "2024-10-01T05:08:04.338491Z",
          "shell.execute_reply.started": "2024-10-01T05:08:04.323313Z",
          "shell.execute_reply": "2024-10-01T05:08:04.337196Z"
        },
        "trusted": true,
        "id": "V3603w_czebf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Prepare Data:\n",
        "\n",
        "    imagesand labels lists are initialized to store the image data and corresponding annotations.\n",
        "    max_annotations variable keeps track of the maximum number of annotations per image.\n",
        "    Iterate over the image files in the image_dir directory:\n",
        "\n",
        "    Read the image and resize it to (224, 224) for consistency.\n",
        "    Load the corresponding annotations from the annotation file.\n",
        "    Update max_annotations if the current image has more annotations.\n",
        "    Append the image and annotations to the respective lists."
      ],
      "metadata": {
        "id": "GNBsbu5czebh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "images = []\n",
        "labels = []\n",
        "max_annotations = 0  # Keep track of the maximum number of annotations per image\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "  if filename.endswith('.jpg'):\n",
        "    image_path = os.path.join(image_dir, filename)\n",
        "    annotation_file = os.path.join(annotation_dir, filename[:-4] + '.txt')\n",
        "\n",
        "    if os.path.exists(annotation_file):\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.resize(img, (224, 224))  # Resize images to a consistent size\n",
        "      images.append(img)\n",
        "      annotations = load_annotations(annotation_file)\n",
        "\n",
        "      # Update max_annotations if current image has more annotations\n",
        "      max_annotations = max(max_annotations, len(annotations))\n",
        "      labels.append(annotations)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T05:08:21.406145Z",
          "iopub.execute_input": "2024-10-01T05:08:21.406722Z",
          "iopub.status.idle": "2024-10-01T05:08:34.013691Z",
          "shell.execute_reply.started": "2024-10-01T05:08:21.406675Z",
          "shell.execute_reply": "2024-10-01T05:08:34.012369Z"
        },
        "trusted": true,
        "id": "WzjC_cUrzebi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Pad Annotations:\n",
        "\n",
        "    Create a new\n",
        "\n",
        "    padded_labels list to store the padded annotations.\n",
        "    Iterate over each annotation list:\n",
        "        Pad the list with [0, 0, 0, 0, 0] elements until it reaches the max_annotations length.\n",
        "        Append the padded annotation list to padded_labels.\n",
        "\n",
        "> Convert to NumPy Arrays:\n",
        "\n",
        "    Convert the images and padded_labels lists to NumPy arrays for efficient processing.\n",
        "\n",
        "> Split Data:\n",
        "\n",
        "    Split the data into training and testing sets using train_test_split.\n",
        "\n",
        "> Reshape Labels:\n",
        "\n",
        "    Reshape the labels to (num_samples, max_annotations, 5) to match the expected input shape for the model.\n",
        "\n",
        "> Custom Data Generator:\n",
        "\n",
        "    DataGenerator class:\n",
        "        Initializes with the training or testing data and batch size.\n",
        "        Implements the __len__ method to return the number of batches.\n",
        "        Implements the __getitem__ method to yield batches of images and labels.\n",
        "\n",
        "> Create Data Generators:\n",
        "\n",
        "    Create instances of the DataGenerator class for training and testing data."
      ],
      "metadata": {
        "id": "dfE59Cnuzebi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad annotations to ensure consistent shape\n",
        "# Create a new list to store padded labels\n",
        "padded_labels = []\n",
        "for annotation_list in labels:\n",
        "    # Pad with [0, 0, 0, 0, 0] to reach max_annotations length\n",
        "    while len(annotation_list) < max_annotations:\n",
        "        annotation_list.append([0, 0, 0, 0, 0])\n",
        "    padded_labels.append(annotation_list)\n",
        "\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "# Use the padded labels instead of the original labels\n",
        "labels = np.array(padded_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T05:08:41.72921Z",
          "iopub.execute_input": "2024-10-01T05:08:41.729806Z",
          "iopub.status.idle": "2024-10-01T05:08:41.94208Z",
          "shell.execute_reply.started": "2024-10-01T05:08:41.729718Z",
          "shell.execute_reply": "2024-10-01T05:08:41.940774Z"
        },
        "trusted": true,
        "id": "hU7aaJq2zebj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape labels to (num_samples, max_annotations, 5)\n",
        "y_train = y_train.reshape(y_train.shape[0], max_annotations, 5)\n",
        "y_test = y_test.reshape(y_test.shape[0], max_annotations, 5)\n",
        "\n",
        "# Custom data generator\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return np.array(batch_x), np.array(batch_y)\n",
        "\n",
        "# Create data generators\n",
        "train_generator = DataGenerator(X_train, y_train, batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T05:08:55.133079Z",
          "iopub.execute_input": "2024-10-01T05:08:55.133622Z",
          "iopub.status.idle": "2024-10-01T05:08:55.147578Z",
          "shell.execute_reply.started": "2024-10-01T05:08:55.133574Z",
          "shell.execute_reply": "2024-10-01T05:08:55.145175Z"
        },
        "trusted": true,
        "id": "yLRAIRC8zebj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 1. Imports:\n",
        "\n",
        "    tensorflow.keras.layers: Provides building blocks for creating neural network layers.\n",
        "        Conv2D: Convolutional layer for feature extraction from images.\n",
        "        MaxPooling2D: Downsampling layer to reduce spatial dimensions.\n",
        "        Flatten: Flattens the multi-dimensional output into a single dimension.\n",
        "        Dense: Fully-connected layer for learning complex relationships.\n",
        "        Reshape: Reshapes the output tensor to a desired shape.\n",
        "\n",
        ">2. Model Creation:\n",
        "\n",
        "    model = Sequential(): Creates a sequential neural network model.\n",
        "    model.add(): Adds layers to the model sequentially.\n",
        "\n",
        ">3. Convolutional Layers:\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3))):\n",
        "        Creates a convolutional layer with 32 filters, each of size 3x3.\n",
        "        Applies a ReLU activation function for non-linearity.\n",
        "        input_shape specifies the dimensions of the input images (224x224x3 for\n",
        "        RGB channels).\n",
        "        \n",
        "    Similar layers follow, each increasing the number of filters (64, 128) to   extract more complex features.\n",
        "    MaxPooling2D((2, 2)): Downsamples the feature maps by a factor of 2 in both height and width.\n",
        "\n",
        ">4. Flatten:\n",
        "\n",
        "    model.add(Flatten()): Converts the multi-dimensional output from the convolutional layers into a single dimension vector.\n",
        "\n",
        ">5. Dense Layer:\n",
        "\n",
        "    model.add(Dense(128, activation='relu')): Adds a fully-connected layer with 128 neurons.\n",
        "        Applies a ReLU activation function for non-linearity.\n",
        "\n",
        ">6. Reshape and Output Layer (Corrected):\n",
        "\n",
        "    Corrected: model.add(Dense(max_annotations * 5, activation='linear'))\n",
        "        Creates a final dense layer with max_annotations * 5 neurons (assuming 5 values per annotation).\n",
        "        Uses a linear activation ('linear') for regression tasks where the output represents continuous values.\n",
        "    Corrected: model.add(Reshape((max_annotations, 5)))\n",
        "        Reshapes the output from the previous layer to match the expected shape of the labels (number of annotations, 5 values per annotation).\n",
        "        The correction here is using max_annotations (previously a typo) to ensure the correct shape based on the prepared data.\n",
        "\n",
        ">7. Model Compilation:\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae']):\n",
        "        Configures the model for training:\n",
        "            optimizer='adam': Uses the Adam optimization algorithm for efficient weight updates.\n",
        "            loss='mse': Defines the Mean Squared Error (MSE) as the loss function to measure prediction error.\n",
        "            metrics=['mae']: Tracks the Mean Absolute Error (MAE) as an additional performance metric.\n",
        "\n",
        ">8. Training:\n",
        "\n",
        "    validation_generator = DataGenerator(X_test, y_test, batch_size=32):\n",
        "        Creates a DataGenerator instance for providing batches of test data during training.\n",
        "    model.fit(train_generator, validation_data=validation_generator, epochs=10):\n",
        "        Trains the model using the train_generator for training data and validates it against validation_generator.\n",
        "        epochs=10: Specifies the number of training epochs (iterations over the entire training data)."
      ],
      "metadata": {
        "id": "lxv0pzpSzebj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape  # Import Reshape\n",
        "# Create the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Reshape the output to match the labels shape (batch_size, max_annotations, 5)\n",
        "model.add(Dense(max_annotations * 5, activation='linear'))\n",
        "model.add(Reshape((max_annotations, 5)))  # Corrected variable name\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "validation_generator = DataGenerator(X_test, y_test, batch_size=32)\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T05:09:12.965575Z",
          "iopub.execute_input": "2024-10-01T05:09:12.966152Z",
          "iopub.status.idle": "2024-10-01T05:19:41.803028Z",
          "shell.execute_reply.started": "2024-10-01T05:09:12.966104Z",
          "shell.execute_reply": "2024-10-01T05:19:41.801505Z"
        },
        "trusted": true,
        "id": "-wdowHhezebk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hypA3UWHzebk"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}